<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# fb: https://www.facebook.com/2008/fbml">
<head>
    <title>机器学习刷课总结 - TechLoveDeath</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">


    <link href="http://menghao.org/images/favicon.png" rel="icon">

<link rel="canonical" href="http://menghao.org/summary-of-machine-learning-class.html">

        <meta name="author" content="雪山" />
        <meta name="keywords" content="量化,机器学习" />
        <meta name="description" content="最近刷了一些机器学习的课程，做一些简单的总结" />

        <meta property="og:site_name" content="TechLoveDeath" />
        <meta property="og:type" content="article"/>
        <meta property="og:title" content="机器学习刷课总结"/>
        <meta property="og:url" content="http://menghao.org/summary-of-machine-learning-class.html"/>
        <meta property="og:description" content="最近刷了一些机器学习的课程，做一些简单的总结"/>
        <meta property="article:published_time" content="2019-03-29" />
            <meta property="article:section" content="Quant" />
            <meta property="article:tag" content="量化" />
            <meta property="article:tag" content="机器学习" />
            <meta property="article:author" content="雪山" />



    <!-- Bootstrap -->
        <link rel="stylesheet" href="http://menghao.org/theme/css/bootstrap.min.css" type="text/css"/>
    <link href="http://menghao.org/theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="http://menghao.org/theme/css/pygments/native.css" rel="stylesheet">
    <link rel="stylesheet" href="http://menghao.org/theme/css/style.css" type="text/css"/>




</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="http://menghao.org/" class="navbar-brand">
<img class="img-responsive pull-left gap-right" src="http://menghao.org/images/favicon.png" width="24"/> TechLoveDeath            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                        <li >
                            <a href="http://menghao.org/category/android.html">Android</a>
                        </li>
                        <li >
                            <a href="http://menghao.org/category/music.html">Music</a>
                        </li>
                        <li class="active">
                            <a href="http://menghao.org/category/quant.html">Quant</a>
                        </li>
                        <li >
                            <a href="http://menghao.org/category/ri-chang.html">日常</a>
                        </li>
                        <li >
                            <a href="http://menghao.org/category/tech.html">Tech</a>
                        </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->

<!-- Banner -->
<!-- End Banner -->

<!-- Content Container -->
<div class="container">
    <div class="row">
        <div class="col-sm-9">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="http://menghao.org/summary-of-machine-learning-class.html"
                       rel="bookmark"
                       title="Permalink to 机器学习刷课总结">
                        机器学习刷课总结
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="fa fa-calendar"></i><time datetime="2019-03-29T21:32:00+08:00"> Fri 29 March 2019</time>
    </span>





<span class="label label-default">Tags</span>
	<a href="http://menghao.org/tag/liang-hua.html">量化</a>
        /
	<a href="http://menghao.org/tag/ji-qi-xue-xi.html">机器学习</a>
    
</footer><!-- /.post-info -->                    </div>
                </div>
                <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<p>其实我刚刷完ISL的时候我就有种相见恨晚的感觉，但是还是把一些基础完全刷完了再动工，因为这样可能会思路多一些吧。ESL我暂时不打算刷了，现在是实用性的，等需要深入某个算法的时候再看也不迟。</p>
<h2>方差(variance)和偏差(bias)</h2>
<p><strong>方差</strong>：其实就是波动，比如好的枪打在靶上，方差小，集中在小圈里面，差的枪，集中在大圈里面。</p>
<p><strong>偏差</strong>：其实就是离靶心有多远。</p>
<p><img alt="bias variance tradeoff" src="http://sinacloud.net/mhblog/2019/04/bias_and_variance.png"></p>
<p><strong>偏差</strong>可以用train set的原始值和模型预测值做一个统计，所有差值的平方除以样本个数(MSE)。</p>
<p><strong>方差</strong>可以用test set上的MSE来进行统计，在最低点前是不准的，但是也没有特别好的方法统计。</p>
<p>集成学习的方法如bagging用到了一个点：多组观测值预测出来的值做平均会大大降低方差(test set)，最重要的是会大在降低偏差，多个离靶心远的值的平均离靶心越来越近(ISL p45)。</p>
<h2>判别模型和生成模型</h2>
<p><a href="https://blog.csdn.net/qq_20011607/article/details/81744614">参考资料</a> (也可参考lee hongyi 2007 lec5)</p>
<p>其实现有算法里面除了bayesian算法，还有LDA和QDA很像生成模型，其他大部分都是送别模型。</p>
<p>生成模型得假设自变量的分布是有规律的，当然大部分就是gaussian分布。这样就会用用现有的数据估算自变量的模型，再用bayesian去计算条件概率，来进行边界决策。关键看P(x_n|y)</p>
<p>判别模型就没有这个估计，是什么就是什么。</p>
<p>从现在的算法来看，判别模型貌似居多，可能x符合gaussian的并不是很多。是不是可以先云自变量进行模型判定再选择模型呢？</p>
<p>在数据很多的情况下，其实判别模型可能更好，如果x真的很符合gaussian分布，数据也不多，那么生成模型可能更好。</p>
<p><strong>* 注意</strong> data noise很大，可能生成模型也不错，如收益率</p>
<h2>抽样的有放回和无放回</h2>
<p><a href="https://zhuanlan.zhihu.com/p/47922595">知乎的参考</a></p>
<p>用bagging做集成学习时，抽样是用的有放回抽样，boosting没有抽样这一步，每一轮的训练集不变，保是每轮中样本的权重发生了变化。</p>
<ol>
<li>
<p>Bagging + 决策树 = 随机森林</p>
</li>
<li>
<p>AdaBoost + 决策树 = 提升树</p>
</li>
<li>
<p>Gradient Boosting + 决策树 = GBDT</p>
</li>
</ol>
<p>bagging用在比较强，容易过拟合的模型上，比如决策树，为了降低variance
boosting是可能过拟合的，用在容易欠拟合的模型上(当然这只是建议)</p>
<p><strong>Ada boosting</strong>是对boosting的升级，基本原理一样，调整权重的算法不一样。一共有T轮，每轮的结果的权重又不一样，最后把T轮的结果加起来。</p>
<p>Ada boosting有一个神秘的现象，就是增加轮数后，train error已经不再将低了，但是test error还有可能继续降低。svm也有类似的效果。</p>
<p><img alt="Ada Boost" src="http://sinacloud.net/mhblog/2019/04/adaboost_train_test_error.png"></p>
<p><strong>Gradient Boosting</strong>和boosting一样，也是每轮更新模型，但是要用Gradient Descent云minimize一个cost function。</p>
<h2>svd</h2>
<p><a href="http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html">参考资料</a></p>
<p>
$$ 
A=U \Lambda U^{-1}=U \Lambda U^{T}
$$
$$ 
\begin{aligned} A x_{1} &=\lambda_{1} x_{1} \\ A x_{2} &=\lambda_{2} x_{2} \\ & \ldots \\ A x_{m} &=\lambda_{m} x_{m} \end{aligned}
$$
$$ 
U=\left[ \begin{array}{llll}{x_{1}} & {x_{2}} & {\cdots} & {x_{m}}\end{array}\right]
$$
$$ 
\Lambda=\left[ \begin{array}{ccc}{\lambda_{1}} & {\cdots} & {0} \\ {\vdots} & {\ddots} & {\vdots} \\ {0} & {\cdots} & {\lambda_{m}}\end{array}\right]
 $$
</p>

<p>上面是<strong>特征值分解(EVD)</strong>，前提是A为对称陈，就是A等于A的转置。下面是针对任意矩阵的分解SVD</p>
<p>$$ 
A=U \Sigma V^{T}
$$</p>
<p>其中A是M*N，U是m*m正交阵，E是M*N对角阵，V是n*n正交阵</p>
<p>SVD的统计意义就是PCA降维，特征重表示</p>
<h2>降维</h2>
<p>PCA <a href="http://www.cnblogs.com/pinard/p/6239403.html">原理篇</a> <a href="https://www.cnblogs.com/pinard/p/6243025.html">实操篇</a></p>
<p>PCA的使用在实操篇里面已经讲得很好了，有一点我又实测了一下，就是关于PCA().components_，从原理分析，其实PCA只是做了坐标旋转，如果PCA不指定n_components参数的话，其实就是把坐标旋转后的所有信息都保存下来了，如果n_components等于2,那么就是提取前两个方差比较大的维度，数据和投影其实是一样的。</p>
<p>那么components_里面的东西倒底是什么呢？其实就是每个维度的主成分载荷，row是维度，如果取方差最大的维度就是components_[0]。</p>
<p>取了之后呢？可以把该维度的PCA数值算出来，和PCA().transform(X)出来的结果是一样的。公式具体可以参考 ISL中文 P158 6.19</p>
<p><img alt="PCA vs tSNE" src="http://sinacloud.net/mhblog/2019/04/PCA_to_tSNE.jpg"></p>
<p>tSNE 是基于模型的，当然大部分的资产收益率是接近 Gaussian 的，最多是用于可视化，可能降维效果一般般。</p>
<p>Autoencoder或许还不错</p>
<p><img alt="Autoencoder" src="http://sinacloud.net/mhblog/2019/04/autoencoder.png"></p>
<p>Autoencoder 是可逆的，encode 就是降维过程，decode是解码(升维)过程。PCA是特殊的线性Autoencoder模式。</p>
<p>用NN去寻找好的encoder，把decode出来的X~ 和原有的X进行对比，做一个cost function云进行优化</p>
<p><img alt="Autoencoder with NN" src="http://sinacloud.net/mhblog/2019/04/Autoencoder_NN.jpg"></p>
<h2>Latent Variables Model</h2>
<p>中间出现个<a href="https://www.zhihu.com/question/24524693">隐变量模型</a>，对应的模型是LFM(Latent Factor Model)，可能LFM是基于概率，而PCA不是的。LFM是interpret，PCA是represent。这个有空再细看吧。</p>
<p><a href="https://site.douban.com/182577/widget/notes/10567212/note/271336847/">参考1</a></p>
<p><a href="https://en.wikipedia.org/wiki/Latent_variable_model">参考2</a></p>
<p><img alt="Models of Sequential Data" src="http://sinacloud.net/mhblog/2019/04/Models_of_Sequential_Data.jpg"></p>
<h2>HMM</h2>
<p><a href="https://www.cnblogs.com/skyme/p/4651331.html">详细解释</a></p>
<h2>clustering</h2>
<p>k++ mean 好于 k mean，数据标准化或者数据美白能帮助 这些算法，对于计算距离的算法，数据标准化是必需的。</p>
<p><strong>下面是一些常用的距离算法：</strong></p>
<p><img alt="Distance Metric" src="http://sinacloud.net/mhblog/2019/04/Distance_Hierarchical_Clustering_Algorithms.jpg"></p>
<p><strong>一些cluster之间的距离算法：</strong></p>
<p><img alt="Set Distance Metric" src="http://sinacloud.net/mhblog/2019/04/Set_Distance_Clustering.jpg"></p>
<p>金融资产很多是多层结构，如板块划分，这个类聚用多层的类聚算法可能更好。Agglomerative Hierarchical Clustering</p>
<h2>NLP</h2>
<p>用这个主要是通过新闻，社交网络的信息(weibo，雪球等等)对涨跌的影响。</p>
<p>X：某时间段内或者某时间点的新闻(如果有人工标记会大幅提高性能)</p>
<p>Y：新闻出来后对应股价的涨跌</p>
<p>setp1: 分词(lib:jieba pip)</p>
<p>step2: 云掉停止词</p>
<p>step3: 用 1/N code 形成 vector，当然也可以用word2vec方法（更多可以参考lee hongyi 2007）</p>
<p>step4: 
- 求 P(y=1|x_n)(<em>假设y=1代表上涨</em>)</p>
<ul>
<li>
<p>P(x_1|y=1) 把历史上涨的新闻(3000条)中x_1出现的次数(300次) = 300/3000</p>
</li>
<li>
<p>用bayesian定理就可求出 P(y=1|x_n)</p>
</li>
</ul>
<p>tips:</p>
<ul>
<li>一个文档值钱的词出现的词频是很低的，肥尾？所以可以把一些没有用的频次高的词去掉</li>
<li>naive bayesian是NLP用到的东西，这里不细写，到处都有，其实就是求P(y=1|x_n)，但是前提是x_i,x_j条件独立：P(x_i|y, x_j)=P(x_i|y) and P(x|y=1)=P(x_1|y=1)*P(x_2|y=1)，这是典型的生成模型</li>
<li>建议不要从论坛，国家的政策比较有效，雪球还不错，tushare</li>
<li>word2vec 假设30*300的矩阵，每一行是一个词，每行连起来就是一篇文章，再做CNN，CNN的Filter一定要覆盖300,整个宽度，因为一行是一个整体词，不可分割。疑问：CNN做NLP?</li>
<li>可自行维护对上涨或者下跌有影响的词库，自己做2vec，只用库里面的词，其他全当停止词扔掉</li>
</ul>
<h2>RL</h2>
<p>强化学习分两类，一类是基于policy的，就是去learn一个actor(\(\pi \))直接告诉你做什么action，另一类是基于value(\(V(\pi )\))的，去learn一个actor告诉我们什么操作对应value是多少，当然value越大越好，还是越小越好，或者随机取对应的action，都是我们自己定的。</p>
<p>两种结合最好啦</p>
<h3>带模型(model based)和不带模型(model free)</h3>
<p>这里面最重要的就是模型是什么的模型？ T[s,a,s'] state转换模型，R[s,a] reward模型</p>
<p>还记得gbm和ou过程吗？能否应用于此呢？嗯，得好好测测。</p>
<h3>Q learning</h3>
<p>Q learning是基于value的model free方法。</p>
<p>基于state做出action，转到下一个state，并获得reward。</p>
<p><strong>state</strong>: 最值是要注意，不能直接取价格，因为价格从5～10块这样在12块时，机器无法做出决策，因为以前12块没出现过。一定要标准化，或者这种标准化方法：close/SMA</p>
<p><strong>action</strong>: buy,shell,hold</p>
<p><strong>reward</strong>: 直接用daily return会收敛的快一些，用总收益可能比较难算</p>
<p>然后就是state是连续值的问题，我想先把state分成间隔，用数字表示，再把所有的state组合在一块儿。比如 标准化后的close: 0.87 -&gt; 9 , stdev: 34 -&gt;7 ，组合就是97</p>
<p>Q是model free，是基于纯经验的，专家说效果不好，这个嘛得实测一下才行。</p>
<h3>dyna</h3>
<p>dyna 是model free和model based的混合模型，在Q的执行中会学习T和R，s'和r会从T和R中产生，再update Q table。</p>
<p>学T模型貌似就是:Sa往Sb转换的次数/总的转换次数 对的，就是一个转换概率</p>
<p>学习R模型请看 ML 4 trading udacity lec 27 Dyna，有一种简单的示例：\( R^{\prime}[s, a]=(1-\alpha) R[s, a]+\alpha \cdot r \)</p>
<h3>一些比较有用的方法</h3>
<p>DDPG，Dueling DQN，noisy net 请看<a href="https://arxiv.org/abs/1710.02298">Rainbow</a> 这篇论文对RL中的一些方法都做了比对和combine。</p>
<p>A3C 是可以并行计算的混合模型，还可以处理连续问题，还不错，可以深入一下，请参考<a href="https://zhuanlan.zhihu.com/p/32596470">这篇文章</a></p>
<p>高级应用请再重看 lee hongyi RL ("Q-learning(Advanced Tips)")</p>
<h2>cross validation</h2>
<p>其实CV我反复看过好几次，也用到了，那么它的作用倒底是什么呢？</p>
<ol>
<li>跑一次CV得出来的mse或者其他的判定方法的值更稳定，方差小，更准确</li>
<li>mse更准确，这样做超参优化那就更准确了，对，超参优化</li>
</ol>
<h2>激活函数</h2>
<p>貌似sigmoid已经不太看好了，用relu的居多</p>
<h2>cost function</h2>
<p>分类要用 cross entropy，其实logstic分类方法就是用的cross entropy，回归才用MSE类似的function。</p>
<p>而logstic可以想像成sigmoid网络里面的一个神经元。</p>
<h2>sklearn</h2>
<p>这个库确实是非常NB的，可惜现在不支持gpu，gpu主要是支持并行矩阵运算，如果把模型改到gpu可能成本过高。</p>
<p>这个库里面有minimize方法，很全的，如果自己写一些算法做优化可以直接用。</p>
<h2>NN layer</h2>
<p>一般来讲分类问题最后一层用softmax会好一些，因为它的输出在0~1之间，很像概率。</p>
<h2>keras</h2>
<p>keras 是 tensorflow 的封装，应该还是比较广，看一下最近出的一张图：</p>
<p><img alt="kaggle竞赛2016年来最常用的框架" src="http://sinacloud.net/mhblog/2019/04/kaggle_most_common_framework.jpg"></p>
<p>下面是一些应用技巧：</p>
<p><strong>fit中的batch_size和nb_epoch</strong></p>
<p>这就是实践和理论的差距，在实践DNN时其实是分批跑的，就是batch。</p>
<p>batch_size = 500，说明一个batch里面的sample是500个，至于有多少个batch，keras自动处理了，我也不知道具体算法。应该是数据量除以500取整+1吧，最后一个batch可能会少一点</p>
<p>epoch是什么呢？把整个batch跑过一轮叫一个epoch，一般跑个20epoch差不多了。</p>
<p>还有个参数叫shuffle，如果为true，则每次跑epoch前会把sample随机打乱。</p>
<h2>tips</h2>
<p>用类聚的方法先对目标进行分类或许是一个不错的方法</p>
<p><strong>Exploit Explore</strong></p>
<p><a href="https://blog.csdn.net/laolu1573/article/details/84255721">参考</a></p>
<p>选餐厅：</p>
<ul>
<li>Exploitation : 去最喜欢的餐厅</li>
<li>Exploration: 尝试新餐厅</li>
</ul>
<p>挖石油:</p>
<ul>
<li>Exploitation : 继续挖已有的</li>
<li>Exploration: 去新地方挖</li>
</ul>
<p>在线广告:</p>
<ul>
<li>Exploitation : 展示最好的广告</li>
<li>Exploration: 展示些不同的广告</li>
</ul>
<p><strong>B样条</strong></p>
<p><a href="https://www.bilibili.com/video/av17255316/?p=1">BiliBili 视频课程 41min</a></p>
<p>分段低阶函数(bspline中4阶(最高3次幂)比较常用)连接来模拟曲线， 每段的函数是基函数的线性组合，基函数是一套，但是系数不一样，替代高阶函数，其实在ISL中的非线性模型中也有提到</p>
<p>bspline 用到的基函数是Cox - de Boor算法，ISL样条回归里面用到的是一些简单的多项式或者其他。</p>
<p>bspline同时也是一个pip库，在scipy里面也有实现</p>
<div class="highlight"><pre><span></span><code><span class="c1"># https://github.com/johntfoster/bspline</span>

<span class="n">X_min</span> <span class="o">=</span> <span class="mf">4.45</span>
<span class="n">X_max</span> <span class="o">=</span> <span class="mf">66.78</span>

<span class="n">p</span> <span class="o">=</span> <span class="mi">4</span>  <span class="c1"># order of spline (as-is; 3 = cubic, 4: B-spline?)</span>
<span class="n">ncolloc</span> <span class="o">=</span> <span class="mi">12</span>
<span class="c1"># These are the sites to which we would like to interpolate</span>
<span class="n">tau</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">X_min</span><span class="p">,</span> <span class="n">X_max</span><span class="p">,</span> <span class="n">ncolloc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;tau&quot;</span> <span class="p">,</span><span class="n">tau</span><span class="p">)</span>

<span class="c1"># k is a knot vector that adds endpoints repeats as appropriate for a spline of order p</span>
<span class="c1"># To get meaningful results, one should have ncolloc &gt;= p+1</span>
<span class="n">k</span> <span class="o">=</span> <span class="n">splinelab</span><span class="o">.</span><span class="n">aptknt</span><span class="p">(</span><span class="n">tau</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
<span class="n">basis</span> <span class="o">=</span> <span class="n">bspline</span><span class="o">.</span><span class="n">Bspline</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

<span class="c1"># 求出33.9的每个基上的系数 </span>
<span class="n">basis</span><span class="p">(</span><span class="mf">33.9</span><span class="p">)</span> 
</code></pre></div>
            </div>
            <!-- /.entry-content -->
<section class="well" id="related-posts">
    <h4>Related Posts:</h4>
    <ul>
        <li><a href="http://menghao.org/reinforcement-learning.html">强化学习</a></li>
        <li><a href="http://menghao.org/some-traps-of-stock-prices-predicted.html">股价预测的陷阱</a></li>
        <li><a href="http://menghao.org/action-of-bad-ml-model.html">机器学习模型效果不好了怎么办？</a></li>
        <li><a href="http://menghao.org/some_exp_of_two_arg_strategy.html">最近的一些经验总结</a></li>
        <li><a href="http://menghao.org/AdvFinML-Standard-Bars.html">AdvFinML - Standard Bars</a></li>
    </ul>
</section>
        </article>
    </section>

        </div>
        <div class="col-sm-3" id="sidebar">
            <aside>
<!-- Sidebar -->
<section class="well well-sm">
  <ul class="list-group list-group-flush">

<!-- Sidebar/Social -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Social</span></h4>
  <ul class="list-group" id="social">
    <li class="list-group-item"><a href="https://github.com/mhxueshan"><i class="fa fa-github-square fa-lg"></i> Github</a></li>
  </ul>
</li>
<!-- End Sidebar/Social -->

<!-- Sidebar/Tag Cloud -->
<li class="list-group-item">
  <a href="http://menghao.org/"><h4><i class="fa fa-tags fa-lg"></i><span class="icon-label">Tags</span></h4></a>
  <ul class="list-group list-inline tagcloud" id="tags">
    <li class="list-group-item tag-3">
      <a href="http://menghao.org/tag/adb.html">adb</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/advfinml.html">AdvFinML</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="http://menghao.org/tag/android.html">Android</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/can-shu-you-hua.html">参数优化</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/cheng-shou-zhi-biao.html">成熟指标</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/chi-cang-liang.html">持仓量</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/elite3.html">Elite3</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/fifthcircle.html">fifthcircle</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/gai-lu.html">概率</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/gu-piao.html">股票</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/hifi.html">hifi</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="http://menghao.org/tag/ji-qi-xue-xi.html">机器学习</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="http://menghao.org/tag/ji-zhu.html">技术</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/keng.html">坑</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/lai-ci-gou.html">莱茨狗</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="http://menghao.org/tag/liang-hua.html">量化</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/lu-you-qi.html">路由器</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/mongodb.html">mongodb</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/monkey.html">monkey</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/music.html">Music</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/qi-huo.html">期货</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="http://menghao.org/tag/ri-chang.html">日常</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/shi-jian-xu-lie.html">时间序列</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="http://menghao.org/tag/shu-xue.html">数学</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="http://menghao.org/tag/tong-ji.html">统计</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/ubuntu.html">Ubuntu</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/wu-du-quan.html">五度圈</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/xi-tong.html">系统</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/xin-li-xue.html">心理学</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/yi-chuan-suan-fa.html">遗传算法</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="http://menghao.org/tag/yi-wen.html">译文</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="http://menghao.org/tag/ying-wen.html">英文</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="http://menghao.org/tag/yu-le.html">娱乐</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="http://menghao.org/tag/za-tan.html">杂谈</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Tag Cloud -->

<!-- Sidebar/Links -->
<li class="list-group-item">
  <h4><i class="fa fa-external-link-square fa-lg"></i><span class="icon-label">Links</span></h4>
  <ul class="list-group" id="links">
    <li class="list-group-item">
      <a href="http://makerchen.com" target="_blank">MakerChen</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Links -->
  </ul>
</section>
<!-- End Sidebar -->            </aside>
        </div>
    </div>
</div>
<!-- End Content Container -->

<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2022 Bryce
            &middot; Powered by <a href="https://github.com/getpelican/pelican-themes/tree/master/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="http://menghao.org/theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="http://menghao.org/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="http://menghao.org/theme/js/respond.min.js"></script>




</body>
</html>