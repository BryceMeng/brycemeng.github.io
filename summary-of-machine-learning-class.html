<!DOCTYPE html>
<html lang="zh" prefix="og: http://ogp.me/ns# fb: https://www.facebook.com/2008/fbml">
<head>
    <title>机器学习刷课总结 - 雪山</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">


    <link href="/images/favicon.png" rel="icon">

<link rel="canonical" href="/summary-of-machine-learning-class.html">

        <meta name="author" content="雪山" />
        <meta name="keywords" content="量化,机器学习" />
        <meta name="description" content="最近刷了一些机器学习的课程，做一些简单的总结" />

        <meta property="og:site_name" content="雪山" />
        <meta property="og:type" content="article"/>
        <meta property="og:title" content="机器学习刷课总结"/>
        <meta property="og:url" content="/summary-of-machine-learning-class.html"/>
        <meta property="og:description" content="最近刷了一些机器学习的课程，做一些简单的总结"/>
        <meta property="article:published_time" content="2019-03-29" />
            <meta property="article:section" content="量化" />
            <meta property="article:tag" content="量化" />
            <meta property="article:tag" content="机器学习" />
            <meta property="article:author" content="雪山" />


    <!-- Bootstrap -->
        <link rel="stylesheet" href="/theme/css/bootstrap.min.css" type="text/css"/>
    <link href="/theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="/theme/css/pygments/native.css" rel="stylesheet">
    <link rel="stylesheet" href="/theme/css/style.css" type="text/css"/>





    <!-- baidu Statistics -->
	<script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "https://hm.baidu.com/hm.js?a7cd0e317621471e586bf369894135aa";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>


</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
	<div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="/" class="navbar-brand">
<img class="img-responsive pull-left gap-right" src="/images/favicon.png" width="24"/> 雪山            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                        <li >
                            <a href="/category/android.html">Android</a>
                        </li>
                        <li >
                            <a href="/category/ji-zhu.html">技术</a>
                        </li>
                        <li class="active">
                            <a href="/category/liang-hua.html">量化</a>
                        </li>
                        <li >
                            <a href="/category/ri-chang.html">日常</a>
                        </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->
<!-- Banner -->
<!-- End Banner -->
<div class="container">
    <div class="row">
        <div class="col-sm-9">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="/summary-of-machine-learning-class.html"
                       rel="bookmark"
                       title="Permalink to 机器学习刷课总结">
                        机器学习刷课总结
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="fa fa-calendar"></i><time datetime="2019-03-29T21:32:00+08:00"> 五 29 三月 2019</time>
    </span>





<span class="label label-default">Tags</span>
	<a href="/tag/liang-hua.html">量化</a>
        /
	<a href="/tag/ji-qi-xue-xi.html">机器学习</a>
    
</footer><!-- /.post-info -->                    </div>
                </div>
                <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<p>其实我刚刷完ISL的时候我就有种相见恨晚的感觉，但是还是把一些基础完全刷完了再动工，因为这样可能会思路多一些吧。ESL我暂时不打算刷了，现在是实用性的，等需要深入某个算法的时候再看也不迟。</p>
<h2>方差(variance)和偏差(bias)</h2>
<p><strong>方差</strong>：其实就是波动，比如好的枪打在靶上，方差小，集中在小圈里面，差的枪，集中在大圈里面。</p>
<p><strong>偏差</strong>：其实就是离靶心有多远。</p>
<p><img alt="bias variance tradeoff" src="http://sinacloud.net/mhblog/2019/04/bias_and_variance.png"></p>
<p><strong>偏差</strong>可以用train set的原始值和模型预测值做一个统计，所有差值的平方除以样本个数(MSE)。</p>
<p><strong>方差</strong>可以用test set上的MSE来进行统计，在最低点前是不准的，但是也没有特别好的方法统计。</p>
<p>集成学习的方法如bagging用到了一个点：多组观测值预测出来的值做平均会大大降低方差(test set)，最重要的是会大在降低偏差，多个离靶心远的值的平均离靶心越来越近(ISL p45)。</p>
<h2>判别模型和生成模型</h2>
<p><a href="https://blog.csdn.net/qq_20011607/article/details/81744614">参考资料</a> (也可参考lee hongyi 2007 lec5)</p>
<p>其实现有算法里面除了bayesian算法，还有LDA和QDA很像生成模型，其他大部分都是送别模型。</p>
<p>生成模型得假设自变量的分布是有规律的，当然大部分就是gaussian分布。这样就会用用现有的数据估算自变量的模型，再用bayesian去计算条件概率，来进行边界决策。关键看P(x_n|y)</p>
<p>判别模型就没有这个估计，是什么就是什么。</p>
<p>从现在的算法来看，判别模型貌似居多，可能x符合gaussian的并不是很多。是不是可以先云自变量进行模型判定再选择模型呢？</p>
<p>在数据很多的情况下，其实判别模型可能更好，如果x真的很符合gaussian分布，数据也不多，那么生成模型可能更好。</p>
<p><strong>* 注意</strong> data noise很大，可能生成模型也不错，如收益率</p>
<h2>抽样的有放回和无放回</h2>
<p><a href="https://zhuanlan.zhihu.com/p/47922595">知乎的参考</a></p>
<p>用bagging做集成学习时，抽样是用的有放回抽样，boosting没有抽样这一步，每一轮的训练集不变，保是每轮中样本的权重发生了变化。</p>
<ol>
<li>
<p>Bagging + 决策树 = 随机森林</p>
</li>
<li>
<p>AdaBoost + 决策树 = 提升树</p>
</li>
<li>
<p>Gradient Boosting + 决策树 = GBDT</p>
</li>
</ol>
<p>bagging用在比较强，容易过拟合的模型上，比如决策树，为了降低variance
boosting是可能过拟合的，用在容易欠拟合的模型上(当然这只是建议)</p>
<p><strong>Ada boosting</strong>是对boosting的升级，基本原理一样，调整权重的算法不一样。一共有T轮，每轮的结果的权重又不一样，最后把T轮的结果加起来。</p>
<p>Ada boosting有一个神秘的现象，就是增加轮数后，train error已经不再将低了，但是test error还有可能继续降低。svm也有类似的效果。</p>
<p><img alt="Ada Boost" src="http://sinacloud.net/mhblog/2019/04/adaboost_train_test_error.png"></p>
<p><strong>Gradient Boosting</strong>和boosting一样，也是每轮更新模型，但是要用Gradient Descent云minimize一个cost function。</p>
<h2>svd</h2>
<p><a href="http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html">参考资料</a></p>
<p>
$$ 
A=U \Lambda U^{-1}=U \Lambda U^{T}
$$
$$ 
\begin{aligned} A x_{1} &=\lambda_{1} x_{1} \\ A x_{2} &=\lambda_{2} x_{2} \\ & \ldots \\ A x_{m} &=\lambda_{m} x_{m} \end{aligned}
$$
$$ 
U=\left[ \begin{array}{llll}{x_{1}} & {x_{2}} & {\cdots} & {x_{m}}\end{array}\right]
$$
$$ 
\Lambda=\left[ \begin{array}{ccc}{\lambda_{1}} & {\cdots} & {0} \\ {\vdots} & {\ddots} & {\vdots} \\ {0} & {\cdots} & {\lambda_{m}}\end{array}\right]
 $$
</p>

<p>上面是<strong>特征值分解(EVD)</strong>，前提是A为对称陈，就是A等于A的转置。下面是针对任意矩阵的分解SVD</p>
<p>$$ 
A=U \Sigma V^{T}
$$</p>
<p>其中A是M*N，U是m*m正交阵，E是M*N对角阵，V是n*n正交阵</p>
<p>SVD的统计意义就是PCA降维，特征重表示</p>
<h2>降维</h2>
<p><img alt="PCA vs tSNE" src="http://sinacloud.net/mhblog/2019/04/PCA_to_tSNE.jpg"></p>
<h2>NLP</h2>
<p>用这个主要是通过新闻，社交网络的信息(weibo，雪球等等)对涨跌的影响。</p>
<p>X：某时间段内或者某时间点的新闻(如果有人工标记会大幅提高性能)</p>
<p>Y：新闻出来后对应股价的涨跌</p>
<p>setp1: 分词(lib:jieba pip)</p>
<p>step2: 云掉停止词</p>
<p>step3: 用 1/N code 形成 vector，当然也可以用word2vec方法（更多可以参考lee hongyi 2007）</p>
<p>step4: 
- 求 P(y=1|x_n)(<em>假设y=1代表上涨</em>)</p>
<ul>
<li>
<p>P(x_1|y=1) 把历史上涨的新闻(3000条)中x_1出现的次数(300次) = 300/3000</p>
</li>
<li>
<p>用bayesian定理就可求出 P(y=1|x_n)</p>
</li>
</ul>
<p>tips:</p>
<ul>
<li>一个文档值钱的词出现的词频是很低的，肥尾？所以可以把一些没有用的频次高的词去掉</li>
<li>naive bayesian是NLP用到的东西，这里不细写，到处都有，其实就是求P(y=1|x_n)，但是前提是x_i,x_j条件独立：P(x_i|y, x_j)=P(x_i|y) and P(x|y=1)=P(x_1|y=1)*P(x_2|y=1)，这是典型的生成模型</li>
<li>建议不要从论坛，国家的政策比较有效，雪球还不错，tushare</li>
<li>word2vec 假设30*300的矩阵，每一行是一个词，每行连起来就是一篇文章，再做CNN，CNN的Filter一定要覆盖300,整个宽度，因为一行是一个整体词，不可分割。疑问：CNN做NLP?</li>
<li>可自行维护对上涨或者下跌有影响的词库，自己做2vec，只用库里面的词，其他全当停止词扔掉</li>
</ul>
<h2>RL</h2>
<p>强化学习分两类，一类是基于policy的，就是去learn一个actor(\(\pi \))直接告诉你做什么action，另一类是基于value(\(V(\pi )\))的，去learn一个actor告诉我们什么操作对应value是多少，当然value越大越好，还是越小越好，或者随机取对应的action，都是我们自己定的。</p>
<p>两种结合最好啦</p>
<h3>带模型(model based)和不带模型(model free)</h3>
<p>这里面最重要的就是模型是什么的模型？ T[s,a,s'] state转换模型，R[s,a] reward模型</p>
<p>还记得gbm和ou过程吗？能否应用于此呢？嗯，得好好测测。</p>
<h3>Q learning</h3>
<p>Q learning是基于value的model free方法。</p>
<p>基于state做出action，转到下一个state，并获得reward。</p>
<p><strong>state</strong>: 最值是要注意，不能直接取价格，因为价格从5～10块这样在12块时，机器无法做出决策，因为以前12块没出现过。一定要标准化，或者这种标准化方法：close/SMA</p>
<p><strong>action</strong>: buy,shell,hold</p>
<p><strong>reward</strong>: 直接用daily return会收敛的快一些，用总收益可能比较难算</p>
<p>然后就是state是连续值的问题，我想先把state分成间隔，用数字表示，再把所有的state组合在一块儿。比如 标准化后的close: 0.87 -&gt; 9 , stdev: 34 -&gt;7 ，组合就是97</p>
<p>Q是model free，是基于纯经验的，专家说效果不好，这个嘛得实测一下才行。</p>
<h3>dyna</h3>
<p>dyna 是model free和model based的混合模型，在Q的执行中会学习T和R，s'和r会从T和R中产生，再update Q table。</p>
<p>学T模型貌似就是:Sa往Sb转换的次数/总的转换次数 对的，就是一个转换概率</p>
<p>学习R模型请看 ML 4 trading udacity lec 27 Dyna，有一种简单的示例：\( R^{\prime}[s, a]=(1-\alpha) R[s, a]+\alpha \cdot r \)</p>
<h3>一些比较有用的方法</h3>
<p>DDPG，Dueling DQN，noisy net 请看<a href="https://arxiv.org/abs/1710.02298">Rainbow</a> 这篇论文对RL中的一些方法都做了比对和combine。</p>
<p>A3C 是可以并行计算的混合模型，还可以处理连续问题，还不错，可以深入一下，请参考<a href="https://zhuanlan.zhihu.com/p/32596470">这篇文章</a></p>
<p>高级应用请再重看 lee hongyi RL ("Q-learning(Advanced Tips)")</p>
<h2>cross validation</h2>
<p>其实CV我反复看过好几次，也用到了，那么它的作用倒底是什么呢？</p>
<ol>
<li>跑一次CV得出来的mse或者其他的判定方法的值更稳定，方差小，更准确</li>
<li>mse更准确，这样做超参优化那就更准确了，对，超参优化</li>
</ol>
<h2>激活函数</h2>
<p>貌似sigmoid已经不太看好了，用relu的居多</p>
<h2>cost function</h2>
<p>分类要用 cross entropy，其实logstic分类方法就是用的cross entropy，回归才用MSE类似的function。</p>
<p>而logstic可以想像成sigmoid网络里面的一个神经元。</p>
<h2>sklearn</h2>
<p>这个库确实是非常NB的，可惜现在不支持gpu，gpu主要是支持并行矩阵运算，如果把模型改到gpu可能成本过高。</p>
<p>这个库里面有minimize方法，很全的，如果自己写一些算法做优化可以直接用。</p>
<h2>NN layer</h2>
<p>一般来讲分类问题最后一层用softmax会好一些，因为它的输出在0~1之间，很像概率。</p>
<h2>keras</h2>
<p>keras 是 tensorflow 的封装，应该还是比较广，看一下最近出的一张图：</p>
<p><img alt="kaggle竞赛2016年来最常用的框架" src="http://sinacloud.net/mhblog/2019/04/kaggle_most_common_framework.jpg"></p>
<p>下面是一些应用技巧：</p>
<p><strong>fit中的batch_size和nb_epoch</strong></p>
<p>这就是实践和理论的差距，在实践DNN时其实是分批跑的，就是batch。</p>
<p>batch_size = 500，说明一个batch里面的sample是500个，至于有多少个batch，keras自动处理了，我也不知道具体算法。应该是数据量除以500取整+1吧，最后一个batch可能会少一点</p>
<p>epoch是什么呢？把整个batch跑过一轮叫一个epoch，一般跑个20epoch差不多了。</p>
<p>还有个参数叫shuffle，如果为true，则每次跑epoch前会把sample随机打乱。</p>
<h2>tips</h2>
<p>用类聚的方法先对目标进行分类或许是一个不错的方法</p>
            </div>
            <!-- /.entry-content -->
<section class="well" id="related-posts">
    <h4>Related Posts:</h4>
    <ul>
        <li><a href="/action-of-bad-ml-model.html">机器学习模型效果不好了怎么办？</a></li>
        <li><a href="/nature-distribution.html">自然分布</a></li>
        <li><a href="/future-open-interest.html">期货持仓量</a></li>
        <li><a href="/ctp-archive-future-tick-2.html">用CTP接口实现期货交易明细分析(2)</a></li>
        <li><a href="/basis-of-stochastic-calculus-for-finance.html">金融随机分析学习的基础</a></li>
    </ul>
</section>
        </article>
    </section>

        </div>
        <div class="col-sm-3" id="sidebar">
            <aside>
<!-- Sidebar -->
<section class="well well-sm">
  <ul class="list-group list-group-flush">

<!-- Sidebar/Social -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Social</span></h4>
  <ul class="list-group" id="social">
    <li class="list-group-item"><a href="https://github.com/mhxueshan"><i class="fa fa-github-square fa-lg"></i> Github</a></li>
  </ul>
</li>
<!-- End Sidebar/Social -->

<!-- Sidebar/Tag Cloud -->
<li class="list-group-item">
  <a href="/"><h4><i class="fa fa-tags fa-lg"></i><span class="icon-label">Tags</span></h4></a>
  <ul class="list-group list-inline tagcloud" id="tags">
    <li class="list-group-item tag-3">
      <a href="/tag/adb.html">adb</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="/tag/android.html">Android</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/can-shu-you-hua.html">参数优化</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/cheng-shou-zhi-biao.html">成熟指标</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/chi-cang-liang.html">持仓量</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/elite3.html">Elite3</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/gai-lu.html">概率</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/gu-piao.html">股票</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/hifi.html">hifi</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/ji-qi-xue-xi.html">机器学习</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="/tag/ji-zhu.html">技术</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/lai-ci-gou.html">莱茨狗</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="/tag/liang-hua.html">量化</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/lu-you-qi.html">路由器</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/mongodb.html">mongodb</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/monkey.html">monkey</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="/tag/ri-chang.html">日常</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/shi-jian-xu-lie.html">时间序列</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/shu-xue.html">数学</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/tong-ji.html">统计</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/xin-li-xue.html">心理学</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/yi-chuan-suan-fa.html">遗传算法</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/yi-wen.html">译文</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/ying-wen.html">英文</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/yu-le.html">娱乐</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="/tag/za-tan.html">杂谈</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Tag Cloud -->

<!-- Sidebar/Links -->
<li class="list-group-item">
  <h4><i class="fa fa-external-link-square fa-lg"></i><span class="icon-label">Links</span></h4>
  <ul class="list-group" id="links">
    <li class="list-group-item">
      <a href="http://makerchen.com" target="_blank">MakerChen</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Links -->
  </ul>
</section>
<!-- End Sidebar -->            </aside>
        </div>
    </div>
</div>
<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2019 雪山
            &middot; Powered by <a href="https://github.com/getpelican/pelican-themes/tree/master/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="/theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="/theme/js/respond.min.js"></script>



</body>
</html>