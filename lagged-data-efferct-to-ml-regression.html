<!DOCTYPE html>
<html lang="zh" prefix="og: http://ogp.me/ns# fb: https://www.facebook.com/2008/fbml">
<head>
    <title>滞后数据对回归的影响 - 雪山</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">


    <link href="/images/favicon.png" rel="icon">

<link rel="canonical" href="/lagged-data-efferct-to-ml-regression.html">

        <meta name="author" content="雪山" />
        <meta name="keywords" content="量化" />
        <meta name="description" content="lagged correlation 引发的思考" />

        <meta property="og:site_name" content="雪山" />
        <meta property="og:type" content="article"/>
        <meta property="og:title" content="滞后数据对回归的影响"/>
        <meta property="og:url" content="/lagged-data-efferct-to-ml-regression.html"/>
        <meta property="og:description" content="lagged correlation 引发的思考"/>
        <meta property="article:published_time" content="2019-05-11" />
            <meta property="article:section" content="量化" />
            <meta property="article:tag" content="量化" />
            <meta property="article:author" content="雪山" />


    <!-- Bootstrap -->
        <link rel="stylesheet" href="/theme/css/bootstrap.min.css" type="text/css"/>
    <link href="/theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="/theme/css/pygments/native.css" rel="stylesheet">
    <link rel="stylesheet" href="/theme/css/style.css" type="text/css"/>





    <!-- baidu Statistics -->
	<script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "https://hm.baidu.com/hm.js?a7cd0e317621471e586bf369894135aa";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>


</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
	<div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="/" class="navbar-brand">
<img class="img-responsive pull-left gap-right" src="/images/favicon.png" width="24"/> 雪山            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                        <li >
                            <a href="/category/android.html">Android</a>
                        </li>
                        <li >
                            <a href="/category/ji-zhu.html">技术</a>
                        </li>
                        <li class="active">
                            <a href="/category/liang-hua.html">量化</a>
                        </li>
                        <li >
                            <a href="/category/ri-chang.html">日常</a>
                        </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->
<!-- Banner -->
<!-- End Banner -->
<div class="container">
    <div class="row">
        <div class="col-sm-9">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="/lagged-data-efferct-to-ml-regression.html"
                       rel="bookmark"
                       title="Permalink to 滞后数据对回归的影响">
                        滞后数据对回归的影响
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="fa fa-calendar"></i><time datetime="2019-05-11T21:32:00+08:00"> 六 11 五月 2019</time>
    </span>





<span class="label label-default">Tags</span>
	<a href="/tag/liang-hua.html">量化</a>
    
</footer><!-- /.post-info -->                    </div>
                </div>
                <p>最近几天才开始着手研究ML量化，有点晚，个人的预期还是很看好ML在Quant买方策略里的效果。</p>
<p>此篇文章非结论性的文章，只是记录一下学习过程中的想法，大家有兴趣可以探讨。</p>
<p>在看一个kaggle竞赛kernel的时候，发现一个延迟相关性的问题。</p>
<div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">]})</span>

<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;C&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;C&quot;</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;C&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;C&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span>
</pre></div>


<p>结果是：</p>
<blockquote>
<p>1.0</p>
<p>0.07459885356228374</p>
</blockquote>
<p>当时我还是挺震惊的，自己和过去的自己完全不相关了吗？</p>
<p>我再回想一下现在的一些回归方法大部分(<strong>除了RNN这种含有历史信息的模型</strong>)都是 f(X_i)=y_i ，这个i是啥呢？我们做股价数据预测时，i就是时间。 X_i 就是i时刻对应的价格(Price)，成交量(Vol)，特征1(Feature1)，特征2(Feature2) ......组成的向量。这应该是横截面回归，计算时不含有历史信息的。我预测明天的股价时，只用到了今天的信息，与昨天无关。</p>
<p>假如<strong>特征1</strong>的预测性很好，那么我们一般会检测一下特征1和y的相关性，结果应该是不错的。但是万一这个特征1的效果有点滞后，今天的新闻对明天本来没什么影响，经过某些专家解读后对后天的股价产生了影响。实际环境中有没有这样的特征呢？这个我也不太清楚。才入坑ML，这些对我来讲一切都是新的......</p>
<p>如果<strong>特征1</strong>的效果滞后了两天(今天-&gt;后天)，而且我们一般把y会设置成明天的股价变化，那特征1和y的相关性就会发生前面代码中的情况（低相关性）。</p>
<p>来代码测试一下：</p>
<div class="highlight"><pre><span></span><span class="c1"># 用的某篇论文中用GBM产生的股价方法，论文中为stock B，故起名为B</span>
<span class="n">stock_price</span> <span class="o">=</span> <span class="n">B</span><span class="p">(</span><span class="mf">12.0</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">stock_price</span>

<span class="c1"># 计算 log return</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;log_return&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;close&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">diff</span><span class="p">()</span>
<span class="c1"># 把y设置成明天的 log return</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;log_return&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">OFFSET</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># 我自己造的一个未来数据特征，其实就是后天的 log return 加了高斯噪声，我假如是个前天的新闻一定会对今天的股价产生影响</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;Feature1&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;log_return&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="o">-</span><span class="n">OFFSET</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span> <span class="o">+</span> <span class="n">RS</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;log_return&quot;</span><span class="p">]))</span>

<span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>


<p>有未来数据在，按理来讲应该是接近1的相关性才对，但是有偏移，按前面的结论应该相关性很低。</p>
<p>来看一下特征1和y相关性如何</p>
<div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;Feature1&quot;</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;log_return&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;Feature1&quot;</span><span class="p">]))</span>

<span class="o">--------</span> <span class="n">output</span>

<span class="o">-</span><span class="mf">0.02142933034920817</span>
<span class="o">-</span><span class="mf">0.0007564299402125546</span>
</pre></div>


<p>在意料之中，和y基本不相关，和过去的自己也没有关系。直接回归试试看呢？我这里用了<strong>线性回归</strong>和<strong>树模型</strong>回归来进行测试。</p>
<div class="highlight"><pre><span></span><span class="n">make_regress</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="o">--------</span> <span class="n">output</span>

<span class="n">linear</span> <span class="n">regression</span> <span class="n">result</span><span class="p">:</span>
<span class="ow">in</span> <span class="n">sample</span> <span class="n">R</span><span class="o">^</span><span class="mi">2</span><span class="p">:</span> <span class="mf">0.01</span> <span class="n">out</span> <span class="n">sample</span> <span class="n">R</span><span class="o">^</span><span class="mi">2</span><span class="p">:</span> <span class="o">-</span><span class="mf">0.06</span>
<span class="n">ExtraTrees</span> <span class="n">regression</span> <span class="n">result</span><span class="p">:</span>
<span class="ow">in</span> <span class="n">sample</span> <span class="n">R</span><span class="o">^</span><span class="mi">2</span><span class="p">:</span> <span class="mf">0.05</span> <span class="n">out</span> <span class="n">sample</span> <span class="n">R</span><span class="o">^</span><span class="mi">2</span><span class="p">:</span> <span class="o">-</span><span class="mf">0.15</span>
</pre></div>


<p>样本内外的R2是负的，那是基本没有预测作用。如果我做如下一个变换呢？从特征1再衍生出一个特征</p>
<div class="highlight"><pre><span></span><span class="c1"># 新增加一个特征</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;Feature1_shift1&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Feature1&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>


<p>再来进行回归测试</p>
<div class="highlight"><pre><span></span><span class="n">make_regress</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="o">--------</span> <span class="n">output</span>

<span class="n">linear</span> <span class="n">regression</span> <span class="n">result</span><span class="p">:</span>
<span class="ow">in</span> <span class="n">sample</span> <span class="n">R</span><span class="o">^</span><span class="mi">2</span><span class="p">:</span> <span class="mf">0.90</span> <span class="n">out</span> <span class="n">sample</span> <span class="n">R</span><span class="o">^</span><span class="mi">2</span><span class="p">:</span> <span class="mf">0.90</span>
<span class="n">ExtraTrees</span> <span class="n">regression</span> <span class="n">result</span><span class="p">:</span>
<span class="ow">in</span> <span class="n">sample</span> <span class="n">R</span><span class="o">^</span><span class="mi">2</span><span class="p">:</span> <span class="mf">0.87</span> <span class="n">out</span> <span class="n">sample</span> <span class="n">R</span><span class="o">^</span><span class="mi">2</span><span class="p">:</span> <span class="mf">0.86</span>
</pre></div>


<p>结果显而易见，回到了用未来数据进行预测的效果。</p>
<p>当然这个例子有点特殊，实际生活中是不是这样还得去进行测试。如果通过简单的<strong>特征工程</strong>（shift）能增加预测效果，那么哪些特征需要做shift呢？shift多少个周期呢？如果新增出来的特征太多，怎么去评价哪些shift是有用的呢？</p>
<p>欢迎大家一起讨论。最后附上所有测试代码(python3)</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">ExtraTreesRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="n">RS</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">LENGTH</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">OFFSET</span> <span class="o">=</span> <span class="mi">2</span>


<span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>

    <span class="n">sticker</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">sticker</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">sticker</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span>

    <span class="n">split_idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">*</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">split_idx</span><span class="p">]</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">split_idx</span><span class="p">]</span>
    <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">split_idx</span><span class="p">:]</span>
    <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">split_idx</span><span class="p">:]</span>

    <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span>


<span class="k">def</span> <span class="nf">make_regress</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>

    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">split</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

    <span class="n">lr_model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
    <span class="n">lr_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="n">lr_in_sample_r2</span> <span class="o">=</span> <span class="n">lr_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">lr_out_sample_r2</span> <span class="o">=</span> <span class="n">lr_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;linear regression result:&quot;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;in sample R^2: </span><span class="si">%.2f</span><span class="s2"> out sample R^2: </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">lr_in_sample_r2</span><span class="p">,</span> <span class="n">lr_out_sample_r2</span><span class="p">))</span>

    <span class="n">etr_model</span> <span class="o">=</span> <span class="n">ExtraTreesRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">etr_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="n">etr_in_sample_r2</span> <span class="o">=</span> <span class="n">etr_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">etr_out_sample_r2</span> <span class="o">=</span> <span class="n">etr_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;ExtraTrees regression result:&quot;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;in sample R^2: </span><span class="si">%.2f</span><span class="s2"> out sample R^2: </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">etr_in_sample_r2</span><span class="p">,</span> <span class="n">etr_out_sample_r2</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">B</span><span class="p">(</span><span class="n">b0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    gen B price Done</span>

<span class="sd">    param bo: initial price</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">global</span> <span class="n">LENGTH</span>

    <span class="n">mu</span> <span class="o">=</span> <span class="mf">0.003</span>
    <span class="n">delta_t</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mf">251.0</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="mf">0.1</span>

    <span class="n">b_close</span> <span class="o">=</span> <span class="p">[</span><span class="n">b0</span><span class="p">]</span>  <span class="c1"># first price</span>

    <span class="n">n_rand</span> <span class="o">=</span> <span class="n">RS</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">LENGTH</span><span class="p">)</span>   <span class="c1"># N~(0,1) random numbers</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">LENGTH</span><span class="p">):</span>
        <span class="n">b</span> <span class="o">=</span> <span class="nb">pow</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">e</span><span class="p">,</span> <span class="n">mu</span><span class="o">*</span><span class="n">delta_t</span><span class="o">+</span><span class="n">delta</span><span class="o">*</span><span class="n">n_rand</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">delta_t</span><span class="p">))</span> <span class="o">*</span> <span class="n">b_close</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">b_close</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

    <span class="n">dates_idx</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">date_range</span><span class="p">(</span><span class="s1">&#39;20130101&#39;</span><span class="p">,</span> <span class="n">periods</span><span class="o">=</span><span class="n">LENGTH</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s1">&#39;D&#39;</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;close&quot;</span><span class="p">:</span> <span class="n">b_close</span><span class="p">},</span> <span class="n">index</span><span class="o">=</span><span class="n">dates_idx</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">df</span>


<span class="c1"># 用的某篇论文中用GBM产生的股价方法，论文中为stock B，故起名为B</span>
<span class="n">stock_price</span> <span class="o">=</span> <span class="n">B</span><span class="p">(</span><span class="mf">12.0</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">stock_price</span>

<span class="c1"># 计算 log return</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;log_return&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;close&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">diff</span><span class="p">()</span>
<span class="c1"># 把y设置成明天的 log return</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;log_return&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># 我自己造的一个未来数据特征，其实就是后天的 log return 加了高斯噪声，我假如是个前天的新闻一定会对今天的股价产生影响</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;Feature1&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;log_return&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="o">-</span><span class="n">OFFSET</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span> <span class="o">+</span> <span class="n">RS</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;log_return&quot;</span><span class="p">]))</span>

<span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;Feature1&quot;</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;log_return&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;Feature1&quot;</span><span class="p">]))</span>

<span class="n">make_regress</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># 新增加一个特征</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;Feature1_shift1&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Feature1&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">make_regress</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
            </div>
            <!-- /.entry-content -->
<section class="well" id="related-posts">
    <h4>Related Posts:</h4>
    <ul>
        <li><a href="/basis-of-stochastic-calculus-for-finance.html">金融随机分析学习的基础</a></li>
        <li><a href="/some-traps-of-stock-prices-predicted.html">股价预测的陷阱</a></li>
        <li><a href="/world-quant-101-alpha-first.html">WorldQuant 101Alpha</a></li>
        <li><a href="/formar-tools-in-reading-quant-book.html">阅读英文书箱的小工具</a></li>
        <li><a href="/tips-of-linear-algebra.html">线代的一些tips</a></li>
    </ul>
</section>
        </article>
    </section>

        </div>
        <div class="col-sm-3" id="sidebar">
            <aside>
<!-- Sidebar -->
<section class="well well-sm">
  <ul class="list-group list-group-flush">

<!-- Sidebar/Social -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Social</span></h4>
  <ul class="list-group" id="social">
    <li class="list-group-item"><a href="https://github.com/mhxueshan"><i class="fa fa-github-square fa-lg"></i> Github</a></li>
  </ul>
</li>
<!-- End Sidebar/Social -->

<!-- Sidebar/Tag Cloud -->
<li class="list-group-item">
  <a href="/"><h4><i class="fa fa-tags fa-lg"></i><span class="icon-label">Tags</span></h4></a>
  <ul class="list-group list-inline tagcloud" id="tags">
    <li class="list-group-item tag-3">
      <a href="/tag/adb.html">adb</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="/tag/android.html">Android</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/can-shu-you-hua.html">参数优化</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/cheng-shou-zhi-biao.html">成熟指标</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/chi-cang-liang.html">持仓量</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/elite3.html">Elite3</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/gai-lu.html">概率</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/gu-piao.html">股票</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/hifi.html">hifi</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="/tag/ji-qi-xue-xi.html">机器学习</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="/tag/ji-zhu.html">技术</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/keng.html">坑</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/lai-ci-gou.html">莱茨狗</a>
    </li>
    <li class="list-group-item tag-0">
      <a href="/tag/liang-hua.html">量化</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/lu-you-qi.html">路由器</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/mongodb.html">mongodb</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/monkey.html">monkey</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/qi-huo.html">期货</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="/tag/ri-chang.html">日常</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/shi-jian-xu-lie.html">时间序列</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/shu-xue.html">数学</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/tong-ji.html">统计</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/ubuntu.html">Ubuntu</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/xi-tong.html">系统</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/xin-li-xue.html">心理学</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/yi-chuan-suan-fa.html">遗传算法</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/yi-wen.html">译文</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/ying-wen.html">英文</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/yu-le.html">娱乐</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="/tag/za-tan.html">杂谈</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Tag Cloud -->

<!-- Sidebar/Links -->
<li class="list-group-item">
  <h4><i class="fa fa-external-link-square fa-lg"></i><span class="icon-label">Links</span></h4>
  <ul class="list-group" id="links">
    <li class="list-group-item">
      <a href="http://makerchen.com" target="_blank">MakerChen</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Links -->
  </ul>
</section>
<!-- End Sidebar -->            </aside>
        </div>
    </div>
</div>
<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2019 雪山
            &middot; Powered by <a href="https://github.com/getpelican/pelican-themes/tree/master/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="/theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="/theme/js/respond.min.js"></script>



</body>
</html>